{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fundamentals of Computing\n",
    "\n",
    "Before moving to higher-level aspects of software, it is best to review the basic concepts of processing data.  Some of this material will seem obvious, while other aspects can seem unnecessarily low-level, especially for analysts who are accustomed to writing scripts.  However, software engineering requires this finer understanding of how programs work with the hardware.  It will soon become apparent that this level of detail is appropriate for data science."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Types of Data\n",
    "\n",
    "Data comes in many forms which we often refer to by its application source or file extension.  All data have a schema which refers to the metadata describing its structural format, the definition of its values, and any other information necessary for maintaining and processing it.  Some knowledge of schema consistency may be implied, such as versioning of a database or API, as opposed to explicitly written within the files, such as eXtensible Markup Language (XML).\n",
    "\n",
    "Schema consistency also relates to versioning of the application that maintains the data.  Application version is typically defined by an increasing sequece of values with the format: MAJOR.MINOR.PATCH, referring to changes: \n",
    "\n",
    "* MAJOR version - incompatible API changes\n",
    "* MINOR version - add functionality in a backwards-compatible manner\n",
    "* PATCH version - make backwards-compatible bug fixes\n",
    "\n",
    "We can loosely categorize data by the consistency and complexity of their schema: structured, semi-structrued, and unstructured.  While the definitions can seem blurry for some types of data, it is a useful lense for viewing this medium.\n",
    "\n",
    "__Structured__  This data is typically tabular​ in form.  Examples may be a database table or file with format Comma Separated Values (.csv), Tab Delimited Values (.tdv, .tsv, .txt), Microsoft Excel (.xlsx) or one of its many derivatives​.  These schemas only change with major (the first number) versions​ of the software applcations that produce them.  In the case of a SQL database, making a major version change is expensive for both the consumers of the data, as well as the maintainers of the database.  So, this rarely occurs for more mature sources.\n",
    "\n",
    "Traditionally, statisticians sought 'long-formatted' data, which referred to many records with a handful (<30) of columns - one for each variable.  However, in the last few decades, the juxtapose can occur.  This may be a few records that are very costly to obtain, but each record contains hundreds of variables.  This type of data requires completely different approaches to traditional methods.\n",
    "\n",
    "__Semi-structured​__ This data is often nested in a tree-like structure, and can be more difficult to parse into a form useful for typical statistical models.  Important formats include JavaScript Object Notation (.json) from web app APIs, HyperText Markup Language (.html) of served web pages, eXtensible Markup Language (.xml) of older database systems, and Portable Document Format (.pdf) used in most business files.  The eXtensible Business Reporting Language (.xbrl) became more prevalent in financial accounting, over the last few years.\n",
    "\n",
    "Schemas may be descriptive, partial, or evolving​ which can lend to even more difficulties in longitudinal projects.  Due to the mutable nature of their format, the schema usually explicitly provides versioning information and other metadata, within the file, to support consumers.  While this type of data may seem unfamiliar to new data practiciioners, it is ubiquitous in the information technology field because of the predominance of web technologies producing data for humans and machines.\n",
    "\n",
    "__Unstructured​__ Such data is usually used by AI practictioners because of the unprocessed openness of its form.  Natural language text may be come from communications data, such as Email (.eml), Calendar data (.ics), and reports (.txt, .docx, .pdf).  It may also be image data which comes in a wide vareity of formats (.jpg, .gif, .png).  This raw data allows more modern models, such as neural networks, to perform feature extraction (or variable selection) as part of the algorithm; rather than separate the tasks in multiple components as is typical of traditional machine learning routines.\n",
    "\n",
    "This data comes unprocessed, directly from the source, which is often a device (or many devices) producing the data.  Schema information may be available for specific devices that create images, but this concept is less relevant when applied to people writing to others.  While feature extraction is moot, preprocessing is much more important.  This standadization may come in a variety of different methods for images and text."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Properties of Big Data\n",
    "\n",
    "Big Data has many challenges which led to the evolution of many disciplines, including data science and data engineering.\n",
    "\n",
    "\n",
    "Volume​\n",
    "\n",
    "Typical problem of many records in long, tabular format​\n",
    "\n",
    "Sometimes have too many columns, or wide format​\n",
    "\n",
    "Text and images may be in many individual files​\n",
    "\n",
    "\n",
    "Velocity​\n",
    "\n",
    "Often refers to ETL pipelines​\n",
    "\n",
    "Data processing can be resource-intensive​\n",
    "\n",
    "\n",
    "Variety​\n",
    "\n",
    "Tabular-, json-, or document-format​\n",
    "\n",
    "Images, email, chat, chat-images and many other forms​"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Constraints and Challenges\n",
    "\n",
    "Von Neuman architecture​\n",
    "\n",
    "Limitation: processing and storage cannot occur at same time​\n",
    "\n",
    "There are many device types for the five components\n",
    "\n",
    "Memory: L1,L2 cache, main​\n",
    "\n",
    "Storage: SSD and Disk read, write​\n",
    "\n",
    "Bus / Route: local, bytes over network, packets across continental cable​\n",
    "\n",
    "'Latency numbers every programmer should know'​\n",
    "\n",
    "​\n",
    "Major trend: Balancing speed with cost is achieved by memory getting cheaper over time (latency numbers)\n",
    "\n",
    "​"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Solutions: Hardware\n",
    "\n",
    "Large server: Grid 128GB​\n",
    "\n",
    "Many large servers: distributed processing​\n",
    "\n",
    "Hadoop: copy function to disk's data​\n",
    "\n",
    "Spark: copy function to memory's data​\n",
    "\n",
    "​\n",
    "\n",
    "Intel vectorization: chip performs common ops on array​\n",
    "\n",
    "Nvidia GPU: chip-level distributed operations​\n",
    "\n",
    "​\n",
    "\n",
    "Combinations of these​"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Solutions: Python Software\n",
    "\n",
    "Constraints​\n",
    "\n",
    "* IO-bound: files and network connections (threading, asycio)​\n",
    "* CPU-bound: matrix inversion (multiprocessing)​\n",
    "\n",
    "__Concurrency__ managing multiple threads at the same time (only running one) on single processor sharing memory​\n",
    "\n",
    "__Parallelism__ multiple processing of jobs, each with its own core (memory, processor, etc.).  Avoids GIL limitations in cPython which only allow a single thread to work on an individual object at a time. ​"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Linux"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get a basic idea of the machine you are working."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#make current\n",
    "! sudo apt-get update && sudo apt-get upgrade"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PRETTY_NAME=\"Debian GNU/Linux 11 (bullseye)\"\n",
      "NAME=\"Debian GNU/Linux\"\n",
      "VERSION_ID=\"11\"\n",
      "VERSION=\"11 (bullseye)\"\n",
      "VERSION_CODENAME=bullseye\n",
      "ID=debian\n",
      "HOME_URL=\"https://www.debian.org/\"\n",
      "SUPPORT_URL=\"https://www.debian.org/support\"\n",
      "BUG_REPORT_URL=\"https://bugs.debian.org/\"\n"
     ]
    }
   ],
   "source": [
    "#os version\n",
    "! cat /etc/os-release"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5.15.49-linuxkit\n"
     ]
    }
   ],
   "source": [
    "#kernel version\n",
    "! uname -r"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4\n"
     ]
    }
   ],
   "source": [
    "#number of core\n",
    "! python -c 'import multiprocessing as mp; print(mp.cpu_count())'\t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "               total        used        free      shared  buff/cache   available\n",
      "Mem:           9.7Gi       1.6Gi       5.1Gi       313Mi       3.1Gi       7.5Gi\n",
      "Swap:          1.0Gi        22Mi       1.0Gi\n"
     ]
    }
   ],
   "source": [
    "! free -h"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "du: cannot access '/home/vagrant/': No such file or directory\n",
      "du: cannot access '/home/ubuntu': No such file or directory\n",
      "464K\t.\n"
     ]
    }
   ],
   "source": [
    "! du --max-depth=1 --human-readable /home/vagrant/ | sort --human-numeric-sort\n",
    "! du -d1 -h /home/ubuntu | sort -h\n",
    "! du -sh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Filesystem      Size  Used Avail Use% Mounted on\n",
      "overlay         110G  102G  3.0G  98% /\n",
      "tmpfs            64M     0   64M   0% /dev\n",
      "shm              64M   24K   64M   1% /dev/shm\n",
      "/dev/vda1       110G  102G  3.0G  98% /vscode\n",
      "grpcfuse        466G  356G  111G  77% /workspaces/ai-for-banking-and-finance\n",
      "tmpfs           4.9G     0  4.9G   0% /proc/acpi\n",
      "tmpfs           4.9G     0  4.9G   0% /sys/firmware\n"
     ]
    }
   ],
   "source": [
    "! df -h"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Inodes keep track of all the files on a Linux system. Except for the file name and the actual content of the file, inodes save everything else. It's like a file-based data structure that holds metadata about all of the files in the system."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Filesystem         Inodes   IUsed      IFree IUse% Mounted on\n",
      "overlay           7340032 3398540    3941492   47% /\n",
      "tmpfs             1275320      16    1275304    1% /dev\n",
      "shm               1275320       7    1275313    1% /dev/shm\n",
      "/dev/vda1         7340032 3398540    3941492   47% /vscode\n",
      "grpcfuse       1154981254 1381414 1153599840    1% /workspaces/ai-for-banking-and-finance\n",
      "tmpfs             1275320       1    1275319    1% /proc/acpi\n",
      "tmpfs             1275320       1    1275319    1% /sys/firmware\n"
     ]
    }
   ],
   "source": [
    "! df -i\t\t#inodes"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CPU and available processes"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Don't be confused by the 'Thread(s) per core'.  This refers to 'virtual components or codes'.  The physical core is separated into, at most, two virtual cores.  So, if a CPU is dual core, then it will have 4 virtual core (displayed here as 'threads')."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Architecture:                    x86_64\n",
      "CPU op-mode(s):                  32-bit, 64-bit\n",
      "Byte Order:                      Little Endian\n",
      "Address sizes:                   39 bits physical, 48 bits virtual\n",
      "CPU(s):                          4\n",
      "On-line CPU(s) list:             0-3\n",
      "Thread(s) per core:              1\n",
      "Core(s) per socket:              4\n",
      "Socket(s):                       1\n",
      "Vendor ID:                       GenuineIntel\n"
     ]
    }
   ],
   "source": [
    "! lscpu | head -n 10"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you want to use the number of cpu's to calculate number of process to spawn, use cpu_count to find the number of cpu's,"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import psutil\n",
    "psutil.cpu_count()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "But using the CPU utilization to calculate the number of spawned processes could be a better approach, to check the CPU utilization, you could do"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "scputimes(user=0.8, nice=0.0, system=1.0, idle=98.2, iowait=0.0, irq=0.0, softirq=0.0, steal=0.0, guest=0.0, guest_nice=0.0)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import psutil\n",
    "psutil.cpu_times_percent(interval=1, percpu=False)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This will give you the cpu usage and for example you could use that information to decide if you want to spawn a new process or not. It might be a good idea to keep an eye on memory and swap too.\n",
    "\n",
    "I think this answer might be useful to look at, Limit total CPU usage in python multiprocessing\n",
    "\n",
    "answered by Radan on [stackoverflow](https://stackoverflow.com/questions/52311339/python-3-multiprocessing-how-many-processes-should-i-use)."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "How many processes should I run in parallel\n",
    "\n",
    "answered by unbuntu on [stackoverflow](https://stackoverflow.com/questions/23816546/how-many-processes-should-i-run-in-parallel)\n",
    "\n",
    "TODO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import multiprocessing as mp\n",
    "\n",
    "def func():\n",
    "    time.sleep(1000)\n",
    "\n",
    "\n",
    "num_workers = mp.cpu_count()  \n",
    "\n",
    "pool = mp.Pool(num_workers)\n",
    "y = 100\n",
    "for task in range(y):\n",
    "    pool.apply_async(func, args = (task,))\n",
    "\n",
    "pool.close()\n",
    "pool.join()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "100"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Threads within Processes"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What is the maximum number of threads I should use?\n",
    "\n",
    "This is answered by [Robert Gamble](https://stackoverflow.com/questions/344203/maximum-number-of-threads-per-process-in-linux) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "78044 threads created.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import threading\n",
    "import time\n",
    "\n",
    "\n",
    "def mythread():\n",
    "    time.sleep(1000)\n",
    "\n",
    "def test_thread_count():\n",
    "    threads = 0     #thread counter\n",
    "    y = 1000000     #a MILLION of 'em!\n",
    "    for i in range(y):\n",
    "        try:\n",
    "            x = threading.Thread(target=mythread, daemon=True)\n",
    "            threads += 1    #thread counter\n",
    "            x.start()       #start each thread\n",
    "        except RuntimeError:    #too many throws a RuntimeError\n",
    "            break\n",
    "    print(\"{} threads created.\\n\".format(threads))\n",
    "\n",
    "test_thread_count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sysctl: cannot stat /proc/sys/kern/num_taskthreads: No such file or directory\n"
     ]
    }
   ],
   "source": [
    "! sysctl kern.num_taskthreads"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Just a limit on the total number of processes on the system (threads are essentially just processes with a shared address space on Linux) which you can view like this:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "78761\n"
     ]
    }
   ],
   "source": [
    "! cat /proc/sys/kernel/threads-max"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The default is the number of memory pages/4.  A page, memory page, or virtual page is a fixed-length contiguous block of virtual memory, described by a single entry in the page table. It is the smallest unit of data for memory management in a virtual memory operating system. \n",
    "\n",
    "You can increase this like:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/bin/bash: line 1: /proc/sys/kernel/threads-max: Read-only file system\n"
     ]
    }
   ],
   "source": [
    "! echo 100000 > /proc/sys/kernel/threads-max"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There is also a limit on the number of processes (and hence threads) that a single user may create, see ulimit/getrlimit for details regarding these limits."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Available Frameworks\n",
    "\n",
    "Scala Spark​\n",
    "\n",
    "R / Py wrapper​\n",
    "\n",
    "Automatic step optimizations​\n",
    "\n",
    "Difficult to install => AWS EMR Cluster​\n",
    "\n",
    "Available in future AWS​\n",
    "\n",
    "​\n",
    "\n",
    "Python Dask​\n",
    "\n",
    "Native python​\n",
    "\n",
    "Easily installed​\n",
    "\n",
    "Used on Grid​\n",
    "\n",
    "Available now​"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13 (main, Aug 25 2022, 23:26:10) \n[GCC 11.2.0]"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "d4d1e4263499bec80672ea0156c357c1ee493ec2b1c70f0acce89fc37c4a6abe"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
